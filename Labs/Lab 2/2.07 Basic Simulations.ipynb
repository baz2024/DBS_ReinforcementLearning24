{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Simulations in OpenAI's Gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI Gym is a toolkit for building, evaluating and comparing RL algorithms. It is\n",
    "compatible with algorithms written in any frameworks like TensoFlow, Theano, Keras etc... It\n",
    "is simple and easy to comprehend. It makes no assumption about the structure of our agent\n",
    "and provides an interface to all RL tasks.\n",
    "\n",
    "Now, we will see, how to simulate environments in gym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CartPole Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let us import the OpenAI's Gym library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the make function for simulating the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we initialize the environment using reset method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.04468519,  0.04008588, -0.01940402,  0.01861113], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we can loop for some time steps and render the environment at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/453543/anaconda3/lib/python3.11/site-packages/gymnasium/envs/classic_control/cartpole.py:215: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/Users/453543/anaconda3/lib/python3.11/site-packages/gymnasium/envs/classic_control/cartpole.py:180: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned terminated = True. You should always call 'reset()' once you receive 'terminated = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Types of Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenAI gym provides a lot of simulation environments for training, evaluating and\n",
    "building our agents. We can check the available environments by either checking their\n",
    "website or simply typing the following commands which will list the available environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gym'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m envs\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(envs\u001b[38;5;241m.\u001b[39mregistry\u001b[38;5;241m.\u001b[39mvalues)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gym'"
     ]
    }
   ],
   "source": [
    "from gym import envs\n",
    "print(envs.registry.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CarRacing Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Since Gym provides different interesting environments, let us simulate a car racing\n",
    "environment as shown below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "#env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "observation, info= env.reset(seed=42)\n",
    "\n",
    "for _ in range(1000):\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated , info = env.step(action)\n",
    "    env.render()\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
